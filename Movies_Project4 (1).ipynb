{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd4f2fba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T00:11:14.724086Z",
     "start_time": "2023-09-15T00:11:14.722067Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_movie_with_rating(movie_id):\n",
    "    \"\"\"Adapted from source = https://github.com/celiao/tmdbsimple\"\"\"\n",
    "    # Get the movie object for the current id\n",
    "    movie = tmdb.Movies(movie_id)\n",
    "    \n",
    "    # save the .info .releases dictionaries\n",
    "    info = movie.info()\n",
    "    \n",
    "    releases = movie.releases()\n",
    "    # Loop through countries in releases\n",
    "    for c in releases['countries']:\n",
    "        # if c['iso_3166_1'] == 'US':\n",
    "        ## save a 'certification' key in info with the certification\n",
    "        info['certification'] = c['certification']\n",
    "        \n",
    "        \n",
    "    return info\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c0ea1aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T00:11:14.726876Z",
     "start_time": "2023-09-15T00:11:14.724701Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        ## Choose extend or append\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ac9c50f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T00:11:14.738334Z",
     "start_time": "2023-09-15T00:11:14.728099Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_and_fix_json(JSON_FILE):\n",
    "    \"\"\"Attempts to read in json file of records and fixes the final character\n",
    "    to end with a ] if it errors.\n",
    "    \n",
    "    Args:\n",
    "        JSON_FILE (str): filepath of JSON file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: the corrected data from the bad json file\n",
    "    \"\"\"\n",
    "    try: \n",
    "        previous_df =  pd.read_json(JSON_FILE)\n",
    "    \n",
    "    ## If read_json throws an error\n",
    "    except:\n",
    "        \n",
    "        ## manually open the json file\n",
    "        with open(JSON_FILE,'r+') as f:\n",
    "            ## Read in the file as a STRING\n",
    "            bad_json = f.read()\n",
    "            \n",
    "            ## if the final character doesn't match first, select the right bracket\n",
    "            first_char = bad_json[0]\n",
    "            final_brackets = {'[':']', \n",
    "                           \"{\":\"}\"}\n",
    "            ## Select expected final brakcet\n",
    "            final_char = final_brackets[first_char]\n",
    "            \n",
    "            ## if the last character in file doen't match the first char, add it\n",
    "            if bad_json[-1] != final_char:\n",
    "                good_json = bad_json[:-1]\n",
    "                good_json+=final_char\n",
    "            else:\n",
    "                raise Exception('ERROR is not due to mismatched final bracket.')\n",
    "            \n",
    "            ## Rewind to start of file and write new good_json to disk\n",
    "            f.seek(0)\n",
    "            f.write(good_json)\n",
    "           \n",
    "        ## Load the json file again now that its fixed\n",
    "        previous_df =  pd.read_json(JSON_FILE)\n",
    "        \n",
    "    return previous_df\n",
    "\t\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9a07453",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-14T23:24:27.569955Z",
     "start_time": "2023-09-14T23:24:27.054678Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# example making new folder with os\n",
    "import os, time,json\n",
    "import tmdbsimple as tmdb \n",
    "FOLDER = \"Data/\"\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "os.listdir(FOLDER)\n",
    "import pymysql\n",
    "pymysql.install_as_MySQLdb()\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import create_database, database_exists\n",
    "from urllib.parse import quote_plus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2188d06a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1748ef2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T00:11:14.720944Z",
     "start_time": "2023-09-15T00:10:22.678458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     titleId  ordering                      title region language  \\\n",
       " 0  tt0000001         1                 Карменсіта     UA       \\N   \n",
       " 1  tt0000001         2                 Carmencita     DE       \\N   \n",
       " 2  tt0000001         3  Carmencita - spanyol tánc     HU       \\N   \n",
       " 3  tt0000001         4                 Καρμενσίτα     GR       \\N   \n",
       " 4  tt0000001         5                 Карменсита     RU       \\N   \n",
       " \n",
       "          types     attributes isOriginalTitle  \n",
       " 0  imdbDisplay             \\N               0  \n",
       " 1           \\N  literal title               0  \n",
       " 2  imdbDisplay             \\N               0  \n",
       " 3  imdbDisplay             \\N               0  \n",
       " 4  imdbDisplay             \\N               0  ,\n",
       "       tconst titleType            primaryTitle           originalTitle  \\\n",
       " 0  tt0000001     short              Carmencita              Carmencita   \n",
       " 1  tt0000002     short  Le clown et ses chiens  Le clown et ses chiens   \n",
       " 2  tt0000003     short          Pauvre Pierrot          Pauvre Pierrot   \n",
       " 3  tt0000004     short             Un bon bock             Un bon bock   \n",
       " 4  tt0000005     short        Blacksmith Scene        Blacksmith Scene   \n",
       " \n",
       "   isAdult startYear endYear runtimeMinutes                    genres  \n",
       " 0       0      1894      \\N              1         Documentary,Short  \n",
       " 1       0      1892      \\N              5           Animation,Short  \n",
       " 2       0      1892      \\N              4  Animation,Comedy,Romance  \n",
       " 3       0      1892      \\N             12           Animation,Short  \n",
       " 4       0      1893      \\N              1              Comedy,Short  ,\n",
       "       tconst  averageRating  numVotes\n",
       " 0  tt0000001            5.7      1993\n",
       " 1  tt0000002            5.8       267\n",
       " 2  tt0000003            6.5      1875\n",
       " 3  tt0000004            5.5       177\n",
       " 4  tt0000005            6.2      2658)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the three files into respective dataframes\n",
    "url_akas = \"https://datasets.imdbws.com/title.akas.tsv.gz\"\n",
    "url_basics = \"https://datasets.imdbws.com/title.basics.tsv.gz\"\n",
    "url_ratings = \"https://datasets.imdbws.com/title.ratings.tsv.gz\"\n",
    "\n",
    "akas_df = pd.read_csv(url_akas, compression='gzip', sep='\\t', low_memory=False)\n",
    "basics_df = pd.read_csv(url_basics, compression='gzip', sep='\\t', low_memory=False)\n",
    "ratings_df = pd.read_csv(url_ratings, compression='gzip', sep='\\t', low_memory=False)\n",
    "\n",
    "# Display the first few rows of each dataframe to understand their structure\n",
    "akas_df.head(), basics_df.head(), ratings_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff6ccc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:17.444409Z",
     "start_time": "2023-09-12T18:11:16.050484Z"
    }
   },
   "outputs": [],
   "source": [
    "akas_df = akas_df[(akas_df['region'] == 'US')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee8e2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:18.498903Z",
     "start_time": "2023-09-12T18:11:17.445244Z"
    }
   },
   "outputs": [],
   "source": [
    "akas_df.replace({'\\\\N': np.nan}, inplace=True)\n",
    "\n",
    "# Display the first few rows of the processed dataframe\n",
    "akas_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633d7a86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:21.115966Z",
     "start_time": "2023-09-12T18:11:18.500472Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter the basics table down to only include the US by using the filter akas dataframe\n",
    "keepers1 =basics_df['tconst'].isin(akas_df['titleId'])\n",
    "keepers1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3816dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:29.505785Z",
     "start_time": "2023-09-12T18:11:21.116749Z"
    }
   },
   "outputs": [],
   "source": [
    "basics_df.replace({'\\\\N': np.nan}, inplace=True)\n",
    "\n",
    "# Display the first few rows of the processed dataframe\n",
    "basics_df.head()\n",
    "basics_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc88de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:29.834112Z",
     "start_time": "2023-09-12T18:11:29.506764Z"
    }
   },
   "outputs": [],
   "source": [
    "basics_df = basics_df[keepers1]\n",
    "basics_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1d4436",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:30.107918Z",
     "start_time": "2023-09-12T18:11:29.835245Z"
    }
   },
   "outputs": [],
   "source": [
    "basics_df = basics_df[basics_df['runtimeMinutes'].notna()]\n",
    "\n",
    "basics_df = basics_df[basics_df['genres'].notna()]\n",
    "\n",
    "basics_df = basics_df[basics_df.titleType == 'movie']\n",
    "\n",
    "basics_df = basics_df[basics_df['startYear'].notna()]\n",
    "\n",
    "basics_df['startYear'] = basics_df['startYear'].astype(float)\n",
    "\n",
    "basics_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd9d20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:30.114817Z",
     "start_time": "2023-09-12T18:11:30.108805Z"
    }
   },
   "outputs": [],
   "source": [
    "basics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183231d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:30.215331Z",
     "start_time": "2023-09-12T18:11:30.115856Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filtering the basics dataframe using startYear column to keep movies between 2000 and 2021 inclusive\n",
    "basics_df = basics_df[(basics_df['startYear'] >= 2000) & (basics_df['startYear'] <= 2021)]\n",
    "basics_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfb0804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:30.314571Z",
     "start_time": "2023-09-12T18:11:30.218095Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exclude movies that are included in the documentary category.\n",
    "is_documentary = basics_df['genres'].str.contains('documentary',case=False)\n",
    "basics_df = basics_df[~is_documentary]\n",
    "basics_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fcb974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:30.423459Z",
     "start_time": "2023-09-12T18:11:30.315428Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings_df.replace({'\\\\N': np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de83af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:30.575529Z",
     "start_time": "2023-09-12T18:11:30.424387Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter the basics table down to only include the US by using the filter akas dataframe\n",
    "keepers2 =ratings_df['tconst'].isin(basics_df['tconst'])\n",
    "keepers2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209f3526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:30.585195Z",
     "start_time": "2023-09-12T18:11:30.576308Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings_df = ratings_df[keepers2]\n",
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d10b6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:39.235800Z",
     "start_time": "2023-09-12T18:11:30.586008Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save Dataframe\n",
    "akas_df.to_csv(\"Data/title_akas.csv.gz\", compression='gzip', index=False)\n",
    "\n",
    "# Open saved file\n",
    "akas_df = pd.read_csv(\"Data/title_akas.csv.gz\", low_memory=False)\n",
    "akas_df.head()\n",
    "akas_df.info() # resubmit added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16db1d98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:39.974994Z",
     "start_time": "2023-09-12T18:11:39.236726Z"
    }
   },
   "outputs": [],
   "source": [
    "basics_df.to_csv(\"Data/title_basics.csv.gz\", compression='gzip' , index=False)\n",
    "\n",
    "#open saved file\n",
    "basics_df = pd.read_csv(\"Data/title_basics.csv.gz\", low_memory=False)\n",
    "basics_df.head()\n",
    "basics_df.info() #resubmit added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31148d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.343240Z",
     "start_time": "2023-09-12T18:11:39.975762Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings_df.to_csv(\"Data/title_ratings.csv.gz\", compression='gzip' , index=False)\n",
    "#open saved file\n",
    "ratings_df = pd.read_csv(\"Data/title_ratings.csv.gz\", low_memory=False)\n",
    "ratings_df.head()\n",
    "ratings_df.info() #resubmit added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f107965",
   "metadata": {},
   "source": [
    "## Using API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e111eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.347286Z",
     "start_time": "2023-09-12T18:11:40.344034Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/Users/corycates/.secret/tmdb_api.json', 'r') as f:\n",
    "    login = json.load(f)\n",
    "## Display the keys of the loaded dict\n",
    "login.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f4653d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.349772Z",
     "start_time": "2023-09-12T18:11:40.347953Z"
    }
   },
   "outputs": [],
   "source": [
    "import tmdbsimple as tmdb\n",
    "tmdb.API_KEY =  login['api-key']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d31920",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.357863Z",
     "start_time": "2023-09-12T18:11:40.350687Z"
    }
   },
   "outputs": [],
   "source": [
    "movie.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695ca3fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.359291Z",
     "start_time": "2023-09-12T18:11:40.359285Z"
    }
   },
   "outputs": [],
   "source": [
    "info['budget']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9a8b6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.360102Z",
     "start_time": "2023-09-12T18:11:40.360096Z"
    }
   },
   "outputs": [],
   "source": [
    "info['revenue']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aad958",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.360990Z",
     "start_time": "2023-09-12T18:11:40.360983Z"
    }
   },
   "outputs": [],
   "source": [
    "info['imdb_id']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc65803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.361915Z",
     "start_time": "2023-09-12T18:11:40.361910Z"
    }
   },
   "outputs": [],
   "source": [
    "# TEST FUNCTION FOR avengers\n",
    "test = get_movie_with_rating(\"tt0848228\") #put your function name here\n",
    "test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9235ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.362685Z",
     "start_time": "2023-09-12T18:11:40.362679Z"
    }
   },
   "outputs": [],
   "source": [
    "# TEST FUNCTION FOR NOTEBOOK\n",
    "test = get_movie_with_rating(\"tt0332280\") #put your function name here\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32950273",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.363316Z",
     "start_time": "2023-09-12T18:11:40.363311Z"
    }
   },
   "outputs": [],
   "source": [
    "YEARS_TO_GET = [2000,2001]\n",
    "\n",
    "YEARS_TO_GET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a62096d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.363826Z",
     "start_time": "2023-09-12T18:11:40.363821Z"
    }
   },
   "outputs": [],
   "source": [
    "# Error list to reference later after the loops\n",
    "errors = [ ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf3087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.364370Z",
     "start_time": "2023-09-12T18:11:40.364364Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook\n",
    "for YEAR in tqdm_notebook(YEARS_TO_GET, desc='YEARS', position=0):\n",
    "    # Some code to execute for each YEAR\n",
    "    print(YEAR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db52dcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.365124Z",
     "start_time": "2023-09-12T18:11:40.365116Z"
    }
   },
   "outputs": [],
   "source": [
    "#Defining the JSON file to store results for year\n",
    "JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb6a71d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.365749Z",
     "start_time": "2023-09-12T18:11:40.365742Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if file exists\n",
    "file_exists = os.path.isfile(JSON_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dcb726",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.366452Z",
     "start_time": "2023-09-12T18:11:40.366447Z"
    }
   },
   "outputs": [],
   "source": [
    "# If it does not exist: create it\n",
    "if file_exists == False:\n",
    "# save an empty dict with just \"imdb_id\" to the new json file.\n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump([{'imdb_id':0}],f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b388251",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.367275Z",
     "start_time": "2023-09-12T18:11:40.367269Z"
    }
   },
   "outputs": [],
   "source": [
    "#Saving new year as the current df\n",
    "current_df = basics_df.loc[ basics_df['startYear']==YEAR].copy()\n",
    "# saving movie ids to list\n",
    "movie_ids = df['tconst'].copy()\n",
    "\n",
    "current_df.head(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaba4f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.367916Z",
     "start_time": "2023-09-12T18:11:40.367910Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load existing data from json into a dataframe called \"previous_df\"\n",
    "previous_df = pd.read_json(JSON_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ee253e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.368513Z",
     "start_time": "2023-09-12T18:11:40.368508Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter out any ids that are already in the JSON_FILE\n",
    "movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e184dc",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Start of the Inner Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b3272a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.369226Z",
     "start_time": "2023-09-12T18:11:40.369221Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    #Get index and movie id from list\n",
    "    # INNER Loop\n",
    "    for movie_id in tqdm(movie_ids_to_get,\n",
    "                                  desc=f'Movies from {YEAR}',\n",
    "                                  position=1,\n",
    "                                  leave=True):\n",
    "        try:\n",
    "            # Retrieve then data for the movie id\n",
    "            temp = get_movie_with_rating(movie_id)  \n",
    "            # Append/extend results to existing file using a pre-made function\n",
    "            write_json(temp,JSON_FILE)\n",
    "            # Short 20 ms sleep to prevent overwhelming server\n",
    "            time.sleep(0.02)\n",
    "            \n",
    "        except Exception as e:\n",
    "            errors.append([movie_id, e])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b0f0c1",
   "metadata": {},
   "source": [
    "## After the Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4188bccb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.446161Z",
     "start_time": "2023-09-12T18:11:40.446155Z"
    }
   },
   "outputs": [],
   "source": [
    "final_year_df = pd.read_json(JSON_FILE)\n",
    "final_year_df.to_csv(f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\", compression=\"gzip\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cee346",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.446823Z",
     "start_time": "2023-09-12T18:11:40.446817Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"- Total errors: {len(errors)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4b0bd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T18:11:40.447547Z",
     "start_time": "2023-09-12T18:11:40.447541Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instead of previous_df=pd.read_json:\n",
    "previous_df = read_and_fix_json(JSON_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad6343f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Part 3 Observation:  All years are appended to one file (2000 and 2001).  To get both years, the for loop needs to be altered to reflect both.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da43b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T22:14:13.226268Z",
     "start_time": "2023-09-12T22:14:13.220347Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create connection string using credentials following this format\n",
    "# connection = \"dialect+driver://username:password@host:port/database\"\n",
    "Movies = \"mysql+pymysql://root:password@localhost:3306/Movies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24561240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T22:14:39.219615Z",
     "start_time": "2023-09-12T22:14:39.210133Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine(Movies)\n",
    "\n",
    "engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc74d99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:26.836774Z",
     "start_time": "2023-09-12T23:07:26.818992Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check if the database exists. If not, create it.\n",
    "if database_exists(Movies) == False:\n",
    "  create_database(Movies)\n",
    "else:\n",
    "  print('The database already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4534d6c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:28.654245Z",
     "start_time": "2023-09-12T23:07:28.042571Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read the files\n",
    "tmdb_data = pd.read_csv(\"Data/final_tmdb_data_2001.csv.gz\", compression='gzip')\n",
    "title_ratings = pd.read_csv(\"Data/title.ratings.tsv.gz\",  compression='gzip', sep=',', low_memory=False)\n",
    "title_basics = pd.read_csv(\"Data/title.basics.csv.gz\", compression='gzip')\n",
    "\n",
    "tmdb_data.head(), title_ratings.head(), title_basics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490d59a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:29.397272Z",
     "start_time": "2023-09-12T23:07:29.297314Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Getting a List of Unique Genres\n",
    "\n",
    "# Convert genre strings into lists in a new 'genres_split' column for basics_df\n",
    "title_basics['genres_split'] = title_basics['genres'].str.split(',')\n",
    "\n",
    "# Explode the lists into new rows\n",
    "exploded_genres_basics = title_basics.explode('genres_split')\n",
    "\n",
    "# Identify and save the unique genres, sorted alphabetically\n",
    "unique_genres_basics = sorted(exploded_genres_basics['genres_split'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8046f2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:30.214211Z",
     "start_time": "2023-09-12T23:07:30.193341Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save just the tconst and genres_split as new df\n",
    "title_genres = exploded_genres[['tconst', 'genres_split']].copy()\n",
    "title_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8658905",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:31.052354Z",
     "start_time": "2023-09-12T23:07:31.044016Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Making the genre mapper dictionary\n",
    "genre_ints = range(len(unique_genres_basics))\n",
    "genre_map = dict(zip(unique_genres_basics, genre_ints))\n",
    "genre_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484b02e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:32.003365Z",
     "start_time": "2023-09-12T23:07:31.976377Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## make new integer genre_id and drop string genres\n",
    "title_genres['genre_id'] = title_genres['genres_split'].map(genre_map)\n",
    "title_genres = title_genres.drop(columns='genres_split')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b47665",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:33.000634Z",
     "start_time": "2023-09-12T23:07:32.986124Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame from the genre_map_basics dictionary\n",
    "genres = pd.DataFrame({'genre_name': list(genre_map_basics.keys()), 'genre_id': list(genre_map_basics.values())})\n",
    "\n",
    "genres.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c00a64e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:33.953608Z",
     "start_time": "2023-09-12T23:07:33.927497Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Drop the unnecessary columns from title_basics\n",
    "title_basics = title_basics.drop(columns=['originalTitle', 'isAdult', 'titleType', 'genres'])\n",
    "\n",
    "title_basics.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f367939",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### II) Saving the MySQL tables with tconst as the primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d7d23f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:37.028166Z",
     "start_time": "2023-09-12T23:07:35.772520Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Set the dataframe index and use index=True \n",
    "title_genres.set_index('genre_id').to_sql('title_genres',engine,index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c5e5b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:37.379235Z",
     "start_time": "2023-09-12T23:07:37.340768Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "genres.set_index('genre_id').to_sql('genres',engine,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a9833a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:38.893448Z",
     "start_time": "2023-09-12T23:07:38.814302Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Getting BLob error...will try an alternative\n",
    "#tmdb_data[['imdb_id', 'revenue', 'budget', 'certification']].set_index('imdb_id').to_sql('tmdb_data', engine, if_exists='replace', index=True)\n",
    "# Define the data types\n",
    "\n",
    "import sqlalchemy\n",
    "\n",
    "# Define the data types\n",
    "data_types = {\n",
    "    'imdb_id': sqlalchemy.types.VARCHAR(length=255),\n",
    "    'revenue': sqlalchemy.types.Float,\n",
    "    'budget': sqlalchemy.types.Float,\n",
    "    'certification': sqlalchemy.types.VARCHAR(length=255)  # Specify a length here\n",
    "}\n",
    "\n",
    "# Use the to_sql function with the dtype parameter\n",
    "tmdb_data[['imdb_id', 'revenue', 'budget', 'certification']].set_index('imdb_id').to_sql(\n",
    "    'tmdb_data', \n",
    "    engine, \n",
    "    if_exists='replace', \n",
    "    index=True, \n",
    "    dtype=data_types\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc194e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:40.326751Z",
     "start_time": "2023-09-12T23:07:40.295485Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## get max string length\n",
    "max_str_len = title_basics['tconst'].fillna('').map(len).max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a715b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:41.487435Z",
     "start_time": "2023-09-12T23:07:41.440995Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy.types import *\n",
    "## Calculate max string lengths for object columns\n",
    "key_len = title_basics['tconst'].fillna('').map(len).max()\n",
    "title_len = title_basics['primaryTitle'].fillna('').map(len).max()\n",
    "## Create a schema dictonary using Sqlalchemy datatype objects\n",
    "df_schema = {\n",
    "    \"tconst\": String(key_len+1), \n",
    "    \"primaryTitle\": Text(title_len+1),\n",
    "    'startYear':Float(),\n",
    "    'runtimeMinutes':Integer()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2065305",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:42.802681Z",
     "start_time": "2023-09-12T23:07:42.266066Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save to sql with dtype and index=False\n",
    "title_basics.to_sql('title_basics',engine,dtype=df_schema,if_exists='replace',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4404d931",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:43.145800Z",
     "start_time": "2023-09-12T23:07:43.125751Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "engine.execute('ALTER TABLE title_basics ADD PRIMARY KEY (`tconst`);')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e9bbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:44.103579Z",
     "start_time": "2023-09-12T23:07:43.896686Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## get max string length\n",
    "max_str_len = title_ratings['tconst'].fillna('').map(len).max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6265e32e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:44.730095Z",
     "start_time": "2023-09-12T23:07:44.524527Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy.types import *\n",
    "## Calculate max string lengths for object columns\n",
    "key_len = title_ratings['tconst'].fillna('').map(len).max()\n",
    "#title_len = title_ratings['primaryTitle'].fillna('').map(len).max()\n",
    "## Create a schema dictonary using Sqlalchemy datatype objects\n",
    "df_schema = {\n",
    "    \"tconst\": String(key_len+1), \n",
    "    'numVotes':Float(),\n",
    "    'averageRating':Integer()}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d4f5ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:56.872518Z",
     "start_time": "2023-09-12T23:07:45.320628Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save to sql with dtype and index=False\n",
    "title_ratings.to_sql('title_ratings',engine,dtype=df_schema,if_exists='replace',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a3dae5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:58.192852Z",
     "start_time": "2023-09-12T23:07:56.873618Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "engine.execute('ALTER TABLE title_ratings ADD PRIMARY KEY (`tconst`);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaddb7ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:58.206969Z",
     "start_time": "2023-09-12T23:07:58.194992Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "genres.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd36892",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:58.213725Z",
     "start_time": "2023-09-12T23:07:58.208878Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "title_basics.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebf5155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:58.217614Z",
     "start_time": "2023-09-12T23:07:58.214513Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "title_genres.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d3f2f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:07:58.223458Z",
     "start_time": "2023-09-12T23:07:58.218552Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "title_ratings.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c728c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:09:23.637107Z",
     "start_time": "2023-09-12T23:09:23.613890Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmdb_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc13f99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T23:09:37.411842Z",
     "start_time": "2023-09-12T23:09:37.392849Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "q = \"\"\"SHOW TABLES;\"\"\"\n",
    "pd.read_sql(q, engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f4d067",
   "metadata": {},
   "source": [
    "# Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83c8b9f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T00:21:48.572297Z",
     "start_time": "2023-09-15T00:21:48.560477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['api-key'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('/Users/corycates/.secret/tmdb_api.json', 'r') as file:\n",
    "    login = json.load(file)\n",
    "## Display the keys of the loaded dict\n",
    "login.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3878ab6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T00:21:49.895721Z",
     "start_time": "2023-09-15T00:21:49.891118Z"
    }
   },
   "outputs": [],
   "source": [
    "import tmdbsimple as tmdb\n",
    "tmdb.API_KEY =  login['api-key']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2403a565",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T00:21:51.425932Z",
     "start_time": "2023-09-15T00:21:51.416896Z"
    }
   },
   "outputs": [],
   "source": [
    "## make a movie object using the .Movies function from tmdb\n",
    "movie = tmdb.Movies(603)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f949b790",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T00:21:53.225920Z",
     "start_time": "2023-09-15T00:21:52.950242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult': False,\n",
       " 'backdrop_path': '/oMsxZEvz9a708d49b6UdZK1KAo5.jpg',\n",
       " 'belongs_to_collection': {'id': 2344,\n",
       "  'name': 'The Matrix Collection',\n",
       "  'poster_path': '/bV9qTVHTVf0gkW0j7p7M0ILD4pG.jpg',\n",
       "  'backdrop_path': '/bRm2DEgUiYciDw3myHuYFInD7la.jpg'},\n",
       " 'budget': 63000000,\n",
       " 'genres': [{'id': 28, 'name': 'Action'},\n",
       "  {'id': 878, 'name': 'Science Fiction'}],\n",
       " 'homepage': 'http://www.warnerbros.com/matrix',\n",
       " 'id': 603,\n",
       " 'imdb_id': 'tt0133093',\n",
       " 'original_language': 'en',\n",
       " 'original_title': 'The Matrix',\n",
       " 'overview': 'Set in the 22nd century, The Matrix tells the story of a computer hacker who joins a group of underground insurgents fighting the vast and powerful computers who now rule the earth.',\n",
       " 'popularity': 73.051,\n",
       " 'poster_path': '/f89U3ADr1oiB1s9GkdPOEpXUk5H.jpg',\n",
       " 'production_companies': [{'id': 79,\n",
       "   'logo_path': '/tpFpsqbleCzEE2p5EgvUq6ozfCA.png',\n",
       "   'name': 'Village Roadshow Pictures',\n",
       "   'origin_country': 'US'},\n",
       "  {'id': 372,\n",
       "   'logo_path': None,\n",
       "   'name': 'Groucho II Film Partnership',\n",
       "   'origin_country': ''},\n",
       "  {'id': 1885,\n",
       "   'logo_path': '/xlvoOZr4s1PygosrwZyolIFe5xs.png',\n",
       "   'name': 'Silver Pictures',\n",
       "   'origin_country': 'US'},\n",
       "  {'id': 174,\n",
       "   'logo_path': '/IuAlhI9eVC9Z8UQWOIDdWRKSEJ.png',\n",
       "   'name': 'Warner Bros. Pictures',\n",
       "   'origin_country': 'US'}],\n",
       " 'production_countries': [{'iso_3166_1': 'US',\n",
       "   'name': 'United States of America'}],\n",
       " 'release_date': '1999-03-30',\n",
       " 'revenue': 463517383,\n",
       " 'runtime': 136,\n",
       " 'spoken_languages': [{'english_name': 'English',\n",
       "   'iso_639_1': 'en',\n",
       "   'name': 'English'}],\n",
       " 'status': 'Released',\n",
       " 'tagline': 'Welcome to the Real World.',\n",
       " 'title': 'The Matrix',\n",
       " 'video': False,\n",
       " 'vote_average': 8.205,\n",
       " 'vote_count': 23760}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## movie objects have a .info dictionary \n",
    "info = movie.info()\n",
    "info\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd61ae5",
   "metadata": {},
   "source": [
    "## Data Analysis on Movie Revenue\n",
    "\n",
    "### Hypothesis 1: \n",
    "#### **Question**: \n",
    "Does the popularity of a movie affect how much revenue the movie generates?\n",
    "\n",
    "- **Null Hypothesis (H0)**: The popularity of a movie does not have any effect on the revenue it generates.\n",
    "- **Alternative Hypothesis (Ha)**: The popularity of a movie does affect the revenue it generates.\n",
    "\n",
    "**Assumptions**:\n",
    "- Revenue data is accurately reported and has no missing values.\n",
    "- Movies with higher popularity scores are not necessarily more popular; they just have different content guidelines.\n",
    "- The sample is representative of the general trend in the movie industry over the selected period.\n",
    "\n",
    "---\n",
    "\n",
    "### Hypothesis 2 (Modified based on available data):\n",
    "#### **Question**: \n",
    "Do movies with higher vote averages earn more revenue?\n",
    "\n",
    "- **Null Hypothesis (H0)**: The vote average of a movie does not have any effect on the revenue it generates.\n",
    "- **Alternative Hypothesis (Ha)**: Movies with higher vote averages earn different revenue than movies with lower vote averages.\n",
    "\n",
    "**Assumptions**:\n",
    "- Vote average is accurately reported.\n",
    "- Movies with higher vote averages do not necessarily have better content; they're just rated higher.\n",
    "- The sample represents movies from various genres, production companies, and target audiences.\n",
    "\n",
    "---\n",
    "\n",
    "### Hypothesis 3:\n",
    "#### **Question**: \n",
    "Do movies released in 2020 earn less revenue than movies released in 2018?\n",
    "\n",
    "- **Null Hypothesis (H0)**: Release year (whether 2020 or 2018) does not affect the revenue of movies.\n",
    "- **Alternative Hypothesis (Ha)**: Movies released in 2020 earn different revenue than movies released in 2018.\n",
    "\n",
    "**Assumptions**:\n",
    "- Release year is accurately reported.\n",
    "- Movies from both years had similar opportunities for marketing and promotions.\n",
    "- External factors, such as global events or market dynamics, are considered when comparing revenues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77798b7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T00:22:12.391182Z",
     "start_time": "2023-09-15T00:22:12.373001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the path to the JSON file\n",
    "json_file_path = '/Users/corycates/Documents/GitHub/Data_Enrichment/Data1/tmdb_api_proj4_2000 - 2022.json'\n",
    "\n",
    "# Load the JSON data into a Pandas DataFrame\n",
    "try:\n",
    "    all_movies_df = pd.read_json(json_file_path)\n",
    "    print(\"Data loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the data: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a454440",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T00:27:12.261741Z",
     "start_time": "2023-09-15T00:27:06.244307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies for 2000 fetched and saved as CSV.\n",
      "Movies for 2001 fetched and saved as CSV.\n",
      "Movies for 2002 fetched and saved as CSV.\n",
      "Movies for 2003 fetched and saved as CSV.\n",
      "Movies for 2004 fetched and saved as CSV.\n",
      "Movies for 2005 fetched and saved as CSV.\n",
      "Movies for 2006 fetched and saved as CSV.\n",
      "Movies for 2007 fetched and saved as CSV.\n",
      "Movies for 2008 fetched and saved as CSV.\n",
      "Movies for 2009 fetched and saved as CSV.\n",
      "Movies for 2010 fetched and saved as CSV.\n",
      "Movies for 2011 fetched and saved as CSV.\n",
      "Movies for 2012 fetched and saved as CSV.\n",
      "Movies for 2013 fetched and saved as CSV.\n",
      "Movies for 2014 fetched and saved as CSV.\n",
      "Movies for 2015 fetched and saved as CSV.\n",
      "Movies for 2016 fetched and saved as CSV.\n",
      "Movies for 2017 fetched and saved as CSV.\n",
      "Movies for 2018 fetched and saved as CSV.\n",
      "Movies for 2019 fetched and saved as CSV.\n",
      "Movies for 2020 fetched and saved as CSV.\n",
      "Movies for 2021 fetched and saved as CSV.\n",
      "Movies for 2022 fetched and saved as CSV.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Replace with your API key\n",
    "API_KEY = \"ffb1d4f5fc2d9aeede7ea943b2b70db0\"\n",
    "\n",
    "# Base URL for fetching movie data\n",
    "BASE_URL = \"https://api.themoviedb.org/3/discover/movie\"\n",
    "\n",
    "# Directory to store the CSV files\n",
    "DIRECTORY = \"/Users/corycates/Documents/GitHub/Data_Enrichment/Data\"\n",
    "\n",
    "# Specify the fields you want from the API\n",
    "# You can customize this list based on the columns you need\n",
    "FIELDS = [\n",
    "    \"title\",\n",
    "    \"overview\",\n",
    "    \"release_date\",\n",
    "    \"popularity\",\n",
    "    \"revenue\",  # Include revenue field\n",
    "    \"vote_average\",  # Include ratings field (vote_average)\n",
    "]\n",
    "\n",
    "# Function to fetch movies for a given year and save them as CSV with selected fields\n",
    "def fetch_movies_for_year(year):\n",
    "    params = {\n",
    "        \"api_key\": API_KEY,\n",
    "        \"primary_release_year\": year,\n",
    "        \"sort_by\": \"popularity.desc\",\n",
    "        \"fields\": \",\".join(FIELDS),  # Convert the list of fields to a comma-separated string\n",
    "    }\n",
    "\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        movies = response.json().get(\"results\", [])\n",
    "        csv_filename = os.path.join(DIRECTORY, f\"movies_{year}.csv\")\n",
    "\n",
    "        with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=FIELDS)\n",
    "            writer.writeheader()\n",
    "            for movie in movies:\n",
    "                writer.writerow({field: movie.get(field, \"\") for field in FIELDS})\n",
    "\n",
    "        print(f\"Movies for {year} fetched and saved as CSV.\")\n",
    "    else:\n",
    "        print(f\"Error fetching movies for {year}: {response.text}\")\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(DIRECTORY, exist_ok=True)\n",
    "\n",
    "# Fetch movies for the years 2000 to 2022 with selected fields and save as CSV\n",
    "for year in range(2000, 2023):\n",
    "    fetch_movies_for_year(year)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e214788",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T00:01:58.345438Z",
     "start_time": "2023-09-15T00:01:58.253168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the DataFrame:\n",
      "   adult                     backdrop_path                    genre_ids  \\\n",
      "0  False  /2u7zbn8EudG6kLlBzUYqP8RyFU4.jpg                 [12, 14, 28]   \n",
      "1  False  /7yxjg8pvp3JuqguUaJPYTma6Z7t.jpg                 [12, 14, 28]   \n",
      "2  False  /1Q1tAM49hoT3Hsj2kpx8O34kG01.jpg  [10751, 16, 12, 35, 14, 28]   \n",
      "3  False  /605ueaRtnDz4Lj3CUluW9wbbh4x.jpg                  [16, 10751]   \n",
      "4  False  /8Id5xQr54BCdVRDQM9i0s8P9BUw.jpg                  [10749, 18]   \n",
      "\n",
      "      id original_language                                     original_title  \\\n",
      "0    122                en      The Lord of the Rings: The Return of the King   \n",
      "1     22                en  Pirates of the Caribbean: The Curse of the Bla...   \n",
      "2  14411                en                   Sinbad: Legend of the Seven Seas   \n",
      "3     12                en                                       Finding Nemo   \n",
      "4  75432                ko                                      맛있는 섹스 그리고 사랑   \n",
      "\n",
      "                                            overview  popularity  \\\n",
      "0  Aragorn is revealed as the heir to the ancient...     100.521   \n",
      "1  Jack Sparrow, a freewheeling 18th-century pira...      84.239   \n",
      "2  The sailor of legend is framed by the goddess ...      73.501   \n",
      "3  Nemo, an adventurous young clownfish, is unexp...      65.078   \n",
      "4  Dong-Ki has one night stand with Shin-Ah, a wo...      51.433   \n",
      "\n",
      "                        poster_path release_date  \\\n",
      "0  /rCzpDGLbOoPwLjy3OAm5NUPOTrC.jpg   2003-12-01   \n",
      "1  /z8onk7LV9Mmw6zKz4hT6pzzvmvl.jpg   2003-07-09   \n",
      "2  /mtkPe9AMiXloYPCsldSbxKuXXWJ.jpg   2003-07-02   \n",
      "3  /ggQ6o8X5984OCh3kZi2UIJQJY5y.jpg   2003-05-30   \n",
      "4  /zu002fbXHiJbtOgKMpOxhb9vJN5.jpg   2003-06-27   \n",
      "\n",
      "                                               title  video  vote_average  \\\n",
      "0      The Lord of the Rings: The Return of the King  False           8.5   \n",
      "1  Pirates of the Caribbean: The Curse of the Bla...  False           7.8   \n",
      "2                   Sinbad: Legend of the Seven Seas  False           6.9   \n",
      "3                                       Finding Nemo  False           7.8   \n",
      "4                                 Sweet Sex and Love  False           4.4   \n",
      "\n",
      "   vote_count  \n",
      "0       22212  \n",
      "1       19181  \n",
      "2        1864  \n",
      "3       18021  \n",
      "4          17  \n",
      "\n",
      "Column names:\n",
      "Index(['adult', 'backdrop_path', 'genre_ids', 'id', 'original_language',\n",
      "       'original_title', 'overview', 'popularity', 'poster_path',\n",
      "       'release_date', 'title', 'video', 'vote_average', 'vote_count'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Using glob to get a list of JSON files\n",
    "json_files = glob.glob(\"/Users/corycates/Documents/GitHub/Data_Enrichment/Data/movies_*.json\")\n",
    "\n",
    "# Step 2: Load the JSON data into DataFrames\n",
    "dataframes = [pd.read_json(json_file) for json_file in json_files]\n",
    "\n",
    "# Step 3: Merge the DataFrames into one comprehensive DataFrame\n",
    "all_movies_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Display the first few rows and column names\n",
    "print(\"First few rows of the DataFrame:\")\n",
    "print(all_movies_df.head())\n",
    "print(\"\\nColumn names:\")\n",
    "print(all_movies_df.columns)\n",
    "\n",
    "# Now you have a single DataFrame 'all_movies_df' containing data from 2000 to 2022.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac30959",
   "metadata": {},
   "source": [
    "## New heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f2143ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T00:36:43.184895Z",
     "start_time": "2023-09-15T00:36:43.154037Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movies_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [50], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Merge the movies and ratings dataframes on the common column 'imdb_id'\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m \u001b[43mmovies_df\u001b[49m\u001b[38;5;241m.\u001b[39mmerge(ratings_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimdb_id\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Now you can visualize the distribution of revenue based on MPAA rating\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'movies_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Merge the movies and ratings dataframes on the common column 'imdb_id'\n",
    "merged_df = movies_df.merge(ratings_df, on='imdb_id', how='left')\n",
    "\n",
    "# Now you can visualize the distribution of revenue based on MPAA rating\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=merged_df, x='mpaa_rating', y='revenue')\n",
    "plt.title('Revenue vs. MPAA Rating')\n",
    "plt.xlabel('MPAA Rating')\n",
    "plt.ylabel('Revenue')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55c221d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T00:17:42.133183Z",
     "start_time": "2023-09-15T00:17:42.117191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>5.8</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000003</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000004</td>\n",
       "      <td>5.5</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst  averageRating  numVotes\n",
       "0  tt0000001            5.7      1993\n",
       "1  tt0000002            5.8       267\n",
       "2  tt0000003            6.5      1875\n",
       "3  tt0000004            5.5       177\n",
       "4  tt0000005            6.2      2658"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba413540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
